
Training step: 1 / 2/work/flemingc/gjbecker/decision-transformer/gym/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/work/flemingc/gjbecker/decision-transformer/gym/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1309: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using non-full backward hooks on a Module that does not return a "
Training step: 2 / 2
Trying RVO
RVO found.

[1.2678859233856201, 1.158421516418457]
============================================================
Iteration 1
time/training: 26.53328514099121
evaluation/target_0.9_return_mean: -0.8877315978484573
evaluation/target_0.9_return_std: 0.030487950113388895
evaluation/target_0.9_length_mean: 51.0
evaluation/target_0.9_length_std: 23.0
evaluation/target_1.0_return_mean: 0.0
evaluation/target_1.0_return_std: 0.0
evaluation/target_1.0_length_mean: 45.0
evaluation/target_1.0_length_std: 0.0
time/total: 30.921179056167603
time/evaluation: 4.387828826904297
training/train_loss_mean: 1.2131537199020386
training/train_loss_std: 0.05473220348358154
training/action_error: 1.158421516418457
============================================================

Training step: 1 / 2Training step: 2 / 2

[1.4884538650512695, 1.3037053346633911]
============================================================
Iteration 2
time/training: 17.274492740631104
evaluation/target_0.9_return_mean: -0.4649131543404488
evaluation/target_0.9_return_std: 0.04180835581734854
evaluation/target_0.9_length_mean: 32.5
evaluation/target_0.9_length_std: 6.5
evaluation/target_1.0_return_mean: -0.947432750416423
evaluation/target_1.0_return_std: 0.40728888869932484
evaluation/target_1.0_length_mean: 31.0
evaluation/target_1.0_length_std: 12.0
time/total: 51.434393882751465
time/evaluation: 3.2365312576293945
training/train_loss_mean: 1.3960795998573303
training/train_loss_std: 0.09237426519393921
training/action_error: 1.3037053346633911
============================================================

Training step: 1 / 2Training step: 2 / 2

[1.6626805067062378, 1.4224402904510498]
============================================================
Iteration 3
time/training: 16.68992304801941
evaluation/target_0.9_return_mean: -0.5224703454257338
evaluation/target_0.9_return_std: 0.5224703454257338
evaluation/target_0.9_length_mean: 56.0
evaluation/target_0.9_length_std: 16.0
evaluation/target_1.0_return_mean: -0.5186824412645867
evaluation/target_1.0_return_std: 0.5186824412645867
evaluation/target_1.0_length_mean: 42.5
evaluation/target_1.0_length_std: 23.5
time/total: 72.1299045085907
time/evaluation: 4.002574682235718
training/train_loss_mean: 1.5425603985786438
training/train_loss_std: 0.120120108127594
training/action_error: 1.4224402904510498
============================================================

Training step: 1 / 2Training step: 2 / 2

[1.0897119045257568, 1.775805115699768]
============================================================
Iteration 4
time/training: 16.912725925445557
evaluation/target_0.9_return_mean: -5.247114455746181
evaluation/target_0.9_return_std: 3.9355429964534823
evaluation/target_0.9_length_mean: 76.5
evaluation/target_0.9_length_std: 34.5
evaluation/target_1.0_return_mean: -0.27363421835776003
evaluation/target_1.0_return_std: 0.27363421835776003
evaluation/target_1.0_length_mean: 44.5
evaluation/target_1.0_length_std: 19.5
time/total: 93.69637608528137
time/evaluation: 4.651355266571045
training/train_loss_mean: 1.4327585101127625
training/train_loss_std: 0.3430466055870056
training/action_error: 1.775805115699768
============================================================
