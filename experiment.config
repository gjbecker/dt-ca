[model]
k = 5
#k = 20
batch_size = 64
model_type = dt
embed_dim = 128
n_layer = 3
n_head = 1
activation_fn = relu
dropout = 0.1
lr = 1e-4
wd = 1e-4
warmup = 10000
wandb = True
state_dim = 4
action_dim = 2
num_eval_episodes = 25
# Default 100
max_iters = 40
# Default 10
num_steps_per_iter = 2500
# Default 10000
device = cuda            
# cuda or cpu
# 5 iters of 2500 steps in ~22 hours on V100
# 8 days to 100,000 total training steps, 1,000 evaluation steps

[env]
env_name = fixed-d4rl
dataset = d4rl.p
mode = normal
max_ep_len = 1500
env_targets = 0.9, 1.0
scale = 1
res = 128
state_mean = 0
state_std = 1
print_logs = True

[checkpoint]
checkpoint = True
resume = False
#load_path = models/mixed_4/20231019-1641.pth

[test]
model_path = models/grid-RVO_4-20231018-2340.pt
env_targets = 0.9, 1.0
multi = False
num_agents = 4
eval_episodes = 500
policies = RVO,RVO,RVO,RVO
# len = num_agents, make sure no space between policies ie. RVO,RVO
seed = 0